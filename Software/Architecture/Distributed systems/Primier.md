---
date: 2022-06-15
tags:
    - scalability
    - redundancy
    - fault-tolerance
---

В процессе жизни веб-приложения возникает вопрос как справляться с возрастающей нагрузкой, т.е. вознкает вопрос масштабирования системы.

**Масштабирование** - это способность системы справляться с возрастающей нагрузкой, например количество пользователей/запросов.

## Вертикальное масштабирование

Это наращивание ресурсов сервера: CPU, RAM, disk. Чем мощнее сервер, тем выше перевариваемая нагрузка.

### Недостатки
1. имеет потолок: все равно когда-то упрешься либо в стоимость сервера, либо в текущие технологические возможности железа
1. высокая стоимость

## Горизонтальное масштабирование

С нагрузкой справляемся за счет добавление новых серверов, которые обрабатывают запросы. Причем характеристики этих серверов могут быть вполне средненькие, а проблема нагрузки решается за счет распределения запросов по этим машинам. Т.е. вместо одного очень мощного(и соответственно очень дорогого) сервера используем несколько средних (и гораздо более дешевых даже в сумме) серверов.

Использование нескольких машин для обработки запросов также повышает отказоустойчивость(*fault-tolerance*) за счет добавленной избыточности(*redundancy*). Если откажет один из серверов, то система в целом останется работоспособной(но возможен и каскадный отказ).

Но в случае горизонтального масштабирования возникает вопрос: как "соединять" клиента с одним из серверов для обработки запроса?

### Балансировка нагрузки

#### DNS

DNS-серверы поддерживают функцию при запросе IP адреса по доменному имени выдавать не конкретный фиксированный адресс, а один из допустимого диапазона. Тогда каждый сервер в системе должен иметь (публичный IP)[https://en.wikipedia.org/wiki/IP_address#Public_address] и эти адреса должны быть указаны в конфигурации DNS.

Недостатокм является то, что IP адрес, полученный от DNS может кэшироваться на разных уровнях(сами DNS серверы, промежуточные узлы сети, ОС, браузер) и на разное время. Это значит, что нагрузка будет банасироваться неравномерно.

#### Балансировщик

Балансировщики могут быть как программными(software), так и физическими(hardware).

Отдельный сервис, который единственный в системе будет иметь публичный IP и принимать все запросы к системе. Дальше он уже будет по какому-то алгоритму передавать эти запросы на выполенние одному из серверов. Серверы в этом случае будут иметь уже приватные IP адреса. Здесь можно реализовать уже более хитрую стратегию балансировки, например учитывать нагрузку на конкретные серверы, чтобы не заваливать и без того нагруженный сервер или слабый по мощности сервер.

**Но**, если каждый запрос может быть направлен на произвольный сервер, то возникает проблема с куки и сессиями, которые будут хранится локально на каждом сервере. Допустим пользователь залогинился на одном сервере, который сохранил локально авторизационные куки, но при уже следующем запросе он снова получит 403, потому что пойдет на соседний сервер, на котором куки нет. И так пока пользователь не залогинится(не появятся куки) на всех серверах.

Чтобы балансировщик не стал единой точкой отказа ему также добавляют избыточности, т.е. вместо одного балансировщика работают два. Могут быть *active-active* или *active-passive* схемы работы.

###### Sticky sessions

Давайте просто направлять все запросы от конкретного пользователя на один и тот же сервер, тогда на нем будут доступны локально хранящиеся данные. Это можно сделать, например, с использованием cookie, которые может устанавливать и интерпретировать сам балансировщик. Проблема в том, что распределение нагрузки становится неравномерным и пользователи с тяжелыми запросами будут продолжать ходить на один и тот же сервер.

##### Shared state

Можно вынести общее состояние(*shared state*) на отдельный сервер и работать с ним как с общей файловой системой(*network file system*) или БД. Но это сразу же привносит единую точку отказа: что толку от множества серверов, если достаточно падения одного, хранящего shared state, чтобы нарушить работу системы.

Частично решить эту проблему может *RAID*(redundant array independent disks) на сервере, хранящим общее состояние. Тогда можно не бояться хотя бы за отказ одного из жестких дисков.

### Кэширование

Сохраняем результат запроса так, чтобы его легко было достать или не нужно было генерировать заново при повторном обращении. Кэширование актуально, когда нагрузка на чтение существенно превосходит нагрузку на запись, иначе придется постоянно инвалидировать кэш и запросы на чтение будут чаще ходить в основное хранилище.

#### Способы:
1. можно отдавать статический контент(файлы) прямо с балансировщика без обращения к серверу и дополнительных вычислений. Это может быть как полностью статичный контент, так и файлы(например html страницы) сгенерированные для конкретных пользователей. Во втором случае проблемой является обновление всех этих страниц при изменении дизайна и то, что требуется много место под уникальные страницы, сгенерированные под разных пользователей.
1. функции кэширования, которые предлагают БД
1. сам сервер в ходе выполнения логики может кэшировать в памяти

### Репликация

Это хранение нескольких копий данных

#### Master-Slave

Вся запись идет на мастер и изменения распространяются на реплики. Чтение может идти с реплик непостредственно

Когда подходит:
1. когда нужна redundancy, чтобы обеспечить fault-tolerance
1. когда нагрузка на чтение существенно превышает запись

Недостатки:
1. при отказе мастера есть down-time пока одна из реплик не будет запромоучена до мастера
1. в зависимости от реализации репликации при записи теоретически возможно потерять данные, если мастер отказал и не успел реплицировать

#### Master-Master

Есть неколько мастеров, которые реплицируют изменения между собой. Плюс у каждого мастера есть реплики. В этом случае если один мастер отказал, то трафик просто переключается на другой без какого-либо down time.

Георепликация может быть реализована на уровне DNS. Я нахожусь в Европе и ввожу google.com, DNS мне выдает IP дата центра, находящегося в Европе. Если я делаю то же самое в Азии, то DNS меня направит в дата центр Азии.

Балансировщики должны принимать только *https* для обеспечения безопасности, а дальше уже можно общаться по *http* тем самым экономим ресурсы на криптографии, не устанавливать ssl сертификаты на каждую машину в дата центре. Балансировщик(или несколько) - это единственна точка входа в датацентр и внутри все безопасно(с высокой доле вероятности)

Балансировщик перед веб серверами может использовать данные запроса для умного роутинга запросов. А вот балансировщик перед серверами БД это делать гораздо сложнее, потому что трафик тут уже в виде бинарных данных, а не строка как в *http*, приходящем в балансировщик перед веб-серверами

---

### Источники:
1. [Lecture 9 Scalability Harvard Web Development David Malan](https://youtu.be/-W9F__D3oY4)

### Ссылки:
1. [[Cascade failure]]
1. [[Replication]]
1. [RAID](https://ru.wikipedia.org/wiki/RAID)
1. [Network file system](https://ru.wikipedia.org/wiki/Network_File_System)
1. [Cache guidelines](https://docs.microsoft.com/en-us/aspnet/core/performance/caching/memory?view=aspnetcore-6.0#cache-guidelines)