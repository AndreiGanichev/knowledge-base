---
date: 2026-01-13
---
# Residual connections

В многослойных сетях активация отдельного нейрона имеет долгосрочное влияние на конечный результат. Другими словами, эффект активации нейрона может распространяться через несколько слоев сети, прежде чем чвнести вклад. Во время обучения информация в модели распространяется в обратном направлении через множество слоев. Это приводит к тому, что обучение идет либо медленно, либо оказывается неэффективным.

В 1991 году Зепп Хохрайтер предложил добавлять **residual connections** в архитектуру сети. Эти соединения работают как короткий путь между не соседними, удаленными друг от друга слоями. Таким образом поток информации проходит мимо одного или нескольких слоев. Благодаря residual connections алгоритм обучения лучше оценивает разницу между входом и желаемым выходом модели.

---

## Источники

1. [[Искусственный интеллект в стратегисческих играх]]

## Ссылки

1. [Vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem)
