---
date: 2025-06-15
---
# History

ИИ появился на стыке нескольких дисциплин:

1. Нейрофизиология

- модель искусственного нейрона и нейронной сети

2. Математика

- правила формальной логики
- статичтические методы
- теория вероятностей
- теория принятия решений

3. Информатика

- языки программирования
- теория вычислительной сложности
- высокопроизводительные компьютеры

4. Кибернетика

- теория управления сложных систем

Термин ИИ был впервые использован в 1956г на Дартмутском семинаре, который дал точкок в развитииновой дисциплины.

ИИ стал развиваться в трех направлениях:

1. символьный подход - задача решается через действия над понятными человеку символическими обозначениями
1. логическое программирование - задача решается методами формальной логики
1. коннекционизм - задача решается сетью связанных между собой простых элементов

В разное время популярным становилось то или иное направления в зависимости от успехов в нем.

## Рассуждение как поиск

Модели Logic theorist (символьный подход) 1956г и Advice Taker (логическое программирование) 1958г использовали концепцию *рассуждение как поиск*:

> Logic theorist выполняет поиск по дереву для доказательства гипотезы. Корень дерева соответствует известным фактам. Исходящие из корня ветви - это логические операции над фактами. Каждая ветвь приводит к определенному выводу. Один из этих выводов является целью рассуждения. Именно его ищет система.

Поиск являлся настолько важной частью, что в процессе создания Advice Taker был разработан декларативный язык программирования *Lisp* (List processing), который был построен на операциях над списками.

## Коннекционизм

В это направление большой вклад внесли ученые нейрофизики, нейропсихологи. Математический аппарат статистической физики был использован для обучения нейронных сетей(сеть Хопфилда).

### Бинарный пороговый нейрон

Имеет два состояния: возбужденное и невозбужденное. На его вход подаются сигналы от других нейронов. Эти сигналы обрабатывает функция активации. Результат функции передается на выход нейрона. Функция активации бинарного порогового нейрона называется ступенчатой: может принимать два значения 0 и 1. Принимает значение 1, когда сумма входных значений превышает определенный порог.

> ..чтобы решать реальные задачи с помощью нейронноей сети, нужны были средства управления. Для универсальных компьютеров такими средствами стали программы. Это решение не подходило для нейронных сетей. Для них нужен был **принципиально иной подход**.

### Перцептрон

Это искусственный нейрон, функция активации которого устроена сложнее. Сигналы на входе теперь не 0 или 1, а вещественные числа. Функция активации - это не просто сумма, но значению на каждом входе добавляется множитель - **вес**.

> ..перцептрон может обучаться. Этот процесс заключается в автоматическом подборе значений весов для каждого входного сигнала.

В 1958г Фрэнк Розенблат сконструировал первый нейрокомпьютер Mark I Perceptron. Он представлял собой однослойную нейронную сеть, предназначался для распознавания изображений и состоял из аналоговых компонентов: нейроны представляли собой электромеханические устройства. На входную матрицу из фотодетекторов подавалось изображение. Результат работы анализировлся человеком и после этого производилась корректировка весов.

### Методы обратного распространения ошибки

Термин ввел Фрэнк Розенблат в 1962г. Суть обучения сети сотояла в подборе весов. Метод обратного распространения ошибки позволял автоматически обучать сеть. Суть его в том, что после прямого прохода на обучающем примере определяется ошибка вычисления и запускается обратный проход. В процессе обратного прохода алгоритм вычисляет вклад каждого веса в общую ошибку вычисления. Далее веса корректируются и повторяется прямой проход.

## Причины бума ИИ

Действительно были успехи в ИИ, обусловленные несколькими факторами:

1. для обучения нейронных сетей было предложено исопльзовать графические процессоры (GPU). Они хорошо подходят из-за того, что имеют большое кол-во ядер и следовательно обеспечивают большую степень парралелизма
1. накопился большой объем данных, которые были использованы для обучения моделей
1. были разработаны эффективные алгоритмы *deep learning*
1. стали доступны фреймворки и библиотеки с открытым исходным кодом для работы с нейронными сетями
1. развитие облачных платформ позволило иметь доступ к большим вычислительным ресурсам

## Deep learning

> Собирательное название для семейства методов машинного обучения. Работают со сложными сетями, имеющими несколько скрытых слоев и сотни параметров.

При обучении разные слои модели работают с разным уровнем абстракции. Например, для изображений это:

1. отдельные линии
1. геометрические фигуры
1. реальные объекты

---

## Источники

1. [[Искусственный интеллект в стратегисческих играх]]

## Ссылки

1. link
