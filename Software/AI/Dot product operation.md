---
date: 2026-01-09
---
# Dot product operation

Скалярное произведение векторов.

> This is a general and simple way of ensuring each output element can be influenced by all the elements in the input vector (where that influence is determined by the weights). Hence its frequent appearance in neural networks.[1]

Используется, например в [[Transformers]] в слое self-attention при работе с Q, K, V матрицами.

> These dot products are a way of measuring the similarity between the two vectors. If they're very similar, the dot product will be large. If they're very different, the dot product will be small or negative.[1]

---

## Источники

1. [LLM Visualization](https://bbycroft.net/llm)

## Ссылки

1. link
